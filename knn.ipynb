{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "00b95d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6dfc010b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_stars                    int64\n",
       "single_planet_exosystem       bool\n",
       "discoverymethod             object\n",
       "disc_year                    int64\n",
       "disc_facility               object\n",
       "                            ...   \n",
       "sy_kmagerr1                float64\n",
       "sy_kmagerr2                float64\n",
       "sy_gaiamag                 float64\n",
       "sy_gaiamagerr1             float64\n",
       "sy_gaiamagerr2             float64\n",
       "Length: 63, dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset\n",
    "df = pd.read_csv('./data/exoplanets-clean.csv')\n",
    "\n",
    "null_col_vals = df.isnull().sum().to_dict()\n",
    "NUM_ROWS = df.shape[0]\n",
    "\n",
    "thresholdAmount = 0.3 * NUM_ROWS\n",
    "\n",
    "dropped = []\n",
    "for key in null_col_vals:\n",
    "    if(null_col_vals[key] >= thresholdAmount):\n",
    "        dropped.append(key)\n",
    "\n",
    "df = df.drop(columns=dropped, axis=1)\n",
    "df = df.dropna()\n",
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b6590a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_stars                    int64\n",
       "single_planet_exosystem       bool\n",
       "discoverymethod              int64\n",
       "disc_year                    int64\n",
       "disc_facility                int64\n",
       "                            ...   \n",
       "sy_kmagerr1                float64\n",
       "sy_kmagerr2                float64\n",
       "sy_gaiamag                 float64\n",
       "sy_gaiamagerr1             float64\n",
       "sy_gaiamagerr2             float64\n",
       "Length: 63, dtype: object"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting Strings to numbers\n",
    "dictMethod = {}\n",
    "count = 0\n",
    "for value in df['discoverymethod']:\n",
    "    if value not in dictMethod:\n",
    "        dictMethod[value] = count\n",
    "        count+=1\n",
    "df['discoverymethod'] = df['discoverymethod'].map(dictMethod)\n",
    "\n",
    "dictFac = {}\n",
    "count2 = 0\n",
    "for value in df['disc_facility']:\n",
    "    if value not in dictFac:\n",
    "        dictFac[value] = count2\n",
    "        count2+=1\n",
    "df['disc_facility'] = df['disc_facility'].map(dictFac)\n",
    "\n",
    "#df['single_planet_exosystem'] = df['single_planet_exosystem'].map({True: 0, False: 1})\n",
    "\n",
    "dictBmass = {}\n",
    "count3 = 0\n",
    "for value in df['pl_bmassprov']:\n",
    "    if value not in dictBmass:\n",
    "        dictBmass[value] = count3\n",
    "        count3+=1\n",
    "df['pl_bmassprov'] = df['pl_bmassprov'].map(dictBmass)\n",
    "\n",
    "dictMratio = {}\n",
    "count4 = 0\n",
    "for value in df['st_metratio']:\n",
    "    if value not in dictMratio:\n",
    "        dictMratio[value] = count4\n",
    "        count4+=1\n",
    "df['st_metratio'] = df['st_metratio'].map(dictMratio)\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7c1a96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "attr = df.drop('single_planet_exosystem', axis=1)\n",
    "target = df['single_planet_exosystem']\n",
    "#attr.head()\n",
    "# target.head()\n",
    "#attr_train, attr_test, target_train,target_test  = train_test_split(attr, target,test_size = 0.25, random_state = 44, shuffle = True)\n",
    "# target_train.head()\n",
    "#attr_train.head()\n",
    "# target_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e37b6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # Initialize MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# # Fit and transform the data\n",
    "# attr = pd.DataFrame(scaler.fit_transform(attr), columns=attr.columns)\n",
    "# attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1e7efc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_stars            int64\n",
      "discoverymethod      int64\n",
      "disc_year            int64\n",
      "disc_facility        int64\n",
      "pl_controv_flag      int64\n",
      "                    ...   \n",
      "sy_kmagerr1        float64\n",
      "sy_kmagerr2        float64\n",
      "sy_gaiamag         float64\n",
      "sy_gaiamagerr1     float64\n",
      "sy_gaiamagerr2     float64\n",
      "Length: 62, dtype: object\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attr_train, attr_test, target_train,target_test  = train_test_split(attr, target,test_size = 0.25, random_state = 3, shuffle = True)\n",
    "target_train.head()\n",
    "# attr_train.head()\n",
    "target_test.head()\n",
    "print(attr_train.dtypes)\n",
    "print(target_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9b4a2ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model with k = 2: 0.6900129701686122%\n",
      "\n",
      "\n",
      "[[333  30]\n",
      " [209 199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.92      0.74       363\n",
      "        True       0.87      0.49      0.62       408\n",
      "\n",
      "    accuracy                           0.69       771\n",
      "   macro avg       0.74      0.70      0.68       771\n",
      "weighted avg       0.75      0.69      0.68       771\n",
      "\n",
      "Accuracy of model with k = 3: 0.6329442282749675%\n",
      "\n",
      "\n",
      "[[247 116]\n",
      " [167 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.68      0.64       363\n",
      "        True       0.68      0.59      0.63       408\n",
      "\n",
      "    accuracy                           0.63       771\n",
      "   macro avg       0.64      0.64      0.63       771\n",
      "weighted avg       0.64      0.63      0.63       771\n",
      "\n",
      "Accuracy of model with k = 4: 0.5784695201037614%\n",
      "\n",
      "\n",
      "[[280  83]\n",
      " [242 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.77      0.63       363\n",
      "        True       0.67      0.41      0.51       408\n",
      "\n",
      "    accuracy                           0.58       771\n",
      "   macro avg       0.60      0.59      0.57       771\n",
      "weighted avg       0.61      0.58      0.57       771\n",
      "\n",
      "Accuracy of model with k = 5: 0.5927367055771725%\n",
      "\n",
      "\n",
      "[[229 134]\n",
      " [180 228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.63      0.59       363\n",
      "        True       0.63      0.56      0.59       408\n",
      "\n",
      "    accuracy                           0.59       771\n",
      "   macro avg       0.59      0.59      0.59       771\n",
      "weighted avg       0.60      0.59      0.59       771\n",
      "\n",
      "Accuracy of model with k = 6: 0.5745784695201037%\n",
      "\n",
      "\n",
      "[[263 100]\n",
      " [228 180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.72      0.62       363\n",
      "        True       0.64      0.44      0.52       408\n",
      "\n",
      "    accuracy                           0.57       771\n",
      "   macro avg       0.59      0.58      0.57       771\n",
      "weighted avg       0.59      0.57      0.57       771\n",
      "\n",
      "Accuracy of model with k = 10: 0.5603112840466926%\n",
      "\n",
      "\n",
      "[[237 126]\n",
      " [213 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.65      0.58       363\n",
      "        True       0.61      0.48      0.53       408\n",
      "\n",
      "    accuracy                           0.56       771\n",
      "   macro avg       0.57      0.57      0.56       771\n",
      "weighted avg       0.57      0.56      0.56       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "k_values = [2,3, 4, 5, 6, 10]\n",
    "\n",
    "#For each k value, getting accruacy and confusion matrix\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(attr_train, target_train)\n",
    "    target_pred = knn.predict(attr_test)\n",
    "#     accuracy = round(np.mean(target_test==target_pred ) * 100, 2)\n",
    "    accuracy = accuracy_score(target_test,target_pred ) \n",
    "    print(f'Accuracy of model with k = {k}: {accuracy}%')\n",
    "    print('')\n",
    "    print('')\n",
    "    print(confusion_matrix(target_test,target_pred))\n",
    "    print(classification_report(target_test,target_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
